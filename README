

# AI HALLUCINATION SPOTTER üéØ

AI Hallucination Spotter Game
AI Hallucination Spotter is an interactive web-based educational game designed to improve users‚Äô ability to detect misinformation generated by artificial intelligence systems.
The application presents users with short factual paragraphs containing one subtly incorrect or ‚Äúhallucinated‚Äù sentence. The user‚Äôs task is to identify the false statement. After each attempt, the system provides instant feedback along with an explanation, helping users understand common patterns of AI hallucinations such as incorrect dates, wrong locations, fabricated statistics, or misattributed facts.
The platform aims to promote digital literacy and critical thinking by training users to evaluate AI-generated content rather than trusting it blindly


### Team Name: COSMIC PAL

### Team Members
- Member 1: Liya Elizabeth Roji - Viswajyothi College of Engineering and Technology , Vazhakulam
-Member 2: Ansa Shibu - Viswajyothi College of Engineering and Technology , Vazhakulam


### Hosted Project Link
[mention your project hosted link here]

It looks like you're setting up the foundation for our discussion. Based on your initial intro, here is a concise way to frame your project description:

Project Description
AI Hallucination Spotter is an interactive educational game that trains users to identify subtle misinformation in AI-generated text. By presenting factual paragraphs with one "hallucinated" sentence, it builds critical thinking skills and improves digital literacy in the age of generative AI.

### The Problem statement
As generative AI tools become widely used in education, research, and daily life, users increasingly rely on AI-generated content. However, AI systems can produce confident but incorrect information, known as hallucinations. Many users lack the skills to identify these inaccuracies, leading to misinformation spread and poor decision-making.

### The Solution
The project provides a gamified learning environment that bridges the gap between AI consumption and critical evaluation. It solves the problem of "blind trust" through three core pillars:
‚Ä¢	Active Engagement (The Spotter Mechanic): Unlike passive reading, the game forces users to scrutinize every sentence. By searching for a specific "glitch," users develop a "skeptic‚Äôs eye" for AI-generated text.
‚Ä¢	Pattern Recognition Training: The game categorizes hallucinations into specific types (e.g., Temporal Errors, Statistical Fabrications, or Logical Inconsistencies). This teaches users the "signatures" of AI failure.


---

## Technical Details

### Technologies/Components Used

**For Software:**
- Languages used: 
HTML5: To structure the game interface and content.
CSS3: For the visual design, animations, and responsive layout.
JavaScript (ES6+): To handle the game logic, user interactions, and state management.
- Frameworks used: Vanilla JS (No Framework): To keep the application lightweight and highly performant.
- Libraries used: Typed.js (Optional suggestion): Often used in these games to simulate the "AI typing" effect
- Tools used:  VS Code, Git


---

## Features

Feature 1: Interactive Hallucination Detection
A dynamic text interface where users can hover over or click individual sentences within a paragraph to "call out" potential AI errors. This simulates real-world fact-checking behavior.

Feature 2: Diverse Hallucination Categories
The game logic draws from a JavaScript-based dataset containing various error types, such as Temporal Errors (wrong dates), Statistical Fabrications (fake numbers), and Misattributed Facts (wrong people/places).

Feature 3: Real-Time Feedback & Detailed Debunking
Upon selecting a sentence, the system provides instant visual feedback (Green for correct, Red for incorrect) alongside a "Truth Card" that explains exactly why the hallucinated sentence was false.

Feature 4: Dynamic Randomized Gameplay
Uses JavaScript logic to shuffle the dataset and present different challenges each session, ensuring that the learning experience remains fresh and repeatable for the user.

Feature 5: Responsive Progress Dashboard
A lightweight scoring system built with CSS and JS that tracks the user's "Accuracy Rating" and "Detection Speed," motivating them to improve their critical thinking skills over time.

---

## Implementation

### For Software:

#### Installation
To run this project locally, you simply need a web browser. No external dependencies are required.


## Project Documentation

### For Software:

#### Screenshots (Add at least 3)


*Add caption explaining what this shows*

![Screenshot2](Add screenshot 2 here with proper name)
*Add caption explaining what this shows*

![Screenshot3](Add screenshot 3 here with proper name)
*Add caption explaining what this shows*

#### Diagrams

**System Architecture:**

![Architecture Diagram](docs/architecture.png)
*Explain your system architecture - components, data flow, tech stack interaction*

**Application Workflow:**

![Workflow](docs/workflow.png)
*Add caption explaining your workflow*

---

### For Hardware:

#### Schematic & Circuit

![Circuit](Add your circuit diagram here)
*Add caption explaining connections*

![Schematic](Add your schematic diagram here)
*Add caption explaining the schematic*

#### Build Photos

![Team](Add photo of your team here)

![Components](Add photo of your components here)
*List out all components shown*

![Build](Add photos of build process here)
*Explain the build steps*

![Final](Add photo of final product here)
*Explain the final build*

---

## Additional Documentation

### For Web Projects with Backend:

#### API Documentation

**Base URL:** `https://api.yourproject.com`

##### Endpoints

**GET /api/endpoint**
- **Description:** [What it does]
- **Parameters:**
  - `param1` (string): [Description]
  - `param2` (integer): [Description]
- **Response:**
```json
{
  "status": "success",
  "data": {}
}
```

**POST /api/endpoint**
- **Description:** [What it does]
- **Request Body:**
```json
{
  "field1": "value1",
  "field2": "value2"
}
```
- **Response:**
```json
{
  "status": "success",
  "message": "Operation completed"
}
```

[Add more endpoints as needed...]

---

### For Mobile Apps:

#### App Flow Diagram

![App Flow](docs/app-flow.png)
*Explain the user flow through your application*

#### Installation Guide

**For Android (APK):**
1. Download the APK from [Release Link]
2. Enable "Install from Unknown Sources" in your device settings:
   - Go to Settings > Security
   - Enable "Unknown Sources"
3. Open the downloaded APK file
4. Follow the installation prompts
5. Open the app and enjoy!

**For iOS (IPA) - TestFlight:**
1. Download TestFlight from the App Store
2. Open this TestFlight link: [Your TestFlight Link]
3. Click "Install" or "Accept"
4. Wait for the app to install
5. Open the app from your home screen

**Building from Source:**
```bash
# For Android
flutter build apk
# or
./gradlew assembleDebug

# For iOS
flutter build ios
# or
xcodebuild -workspace App.xcworkspace -scheme App -configuration Debug
```

---

### For Hardware Projects:

#### Bill of Materials (BOM)

| Component | Quantity | Specifications | Price | Link/Source |
|-----------|----------|----------------|-------|-------------|
| Arduino Uno | 1 | ATmega328P, 16MHz | ‚Çπ450 | [Link] |
| LED | 5 | Red, 5mm, 20mA | ‚Çπ5 each | [Link] |
| Resistor | 5 | 220Œ©, 1/4W | ‚Çπ1 each | [Link] |
| Breadboard | 1 | 830 points | ‚Çπ100 | [Link] |
| Jumper Wires | 20 | Male-to-Male | ‚Çπ50 | [Link] |
| [Add more...] | | | | |

**Total Estimated Cost:** ‚Çπ[Amount]

#### Assembly Instructions

**Step 1: Prepare Components**
1. Gather all components listed in the BOM
2. Check component specifications
3. Prepare your workspace
![Step 1](images/assembly-step1.jpg)
*Caption: All components laid out*

**Step 2: Build the Power Supply**
1. Connect the power rails on the breadboard
2. Connect Arduino 5V to breadboard positive rail
3. Connect Arduino GND to breadboard negative rail
![Step 2](images/assembly-step2.jpg)
*Caption: Power connections completed*

**Step 3: Add Components**
1. Place LEDs on breadboard
2. Connect resistors in series with LEDs
3. Connect LED cathodes to GND
4. Connect LED anodes to Arduino digital pins (2-6)
![Step 3](images/assembly-step3.jpg)
*Caption: LED circuit assembled*

**Step 4: [Continue for all steps...]**

**Final Assembly:**
![Final Build](images/final-build.jpg)
*Caption: Completed project ready for testing*

---

### For Scripts/CLI Tools:

#### Command Reference

**Basic Usage:**
```bash
python script.py [options] [arguments]
```

**Available Commands:**
- `command1 [args]` - Description of what command1 does
- `command2 [args]` - Description of what command2 does
- `command3 [args]` - Description of what command3 does

**Options:**
- `-h, --help` - Show help message and exit
- `-v, --verbose` - Enable verbose output
- `-o, --output FILE` - Specify output file path
- `-c, --config FILE` - Specify configuration file
- `--version` - Show version information

**Examples:**

```bash
# Example 1: Basic usage
python script.py input.txt

# Example 2: With verbose output
python script.py -v input.txt

# Example 3: Specify output file
python script.py -o output.txt input.txt

# Example 4: Using configuration
python script.py -c config.json --verbose input.txt
```

#### Demo Output

**Example 1: Basic Processing**

**Input:**
```
This is a sample input file
with multiple lines of text
for demonstration purposes
```

**Command:**
```bash
python script.py sample.txt
```

**Output:**
```
Processing: sample.txt
Lines processed: 3
Characters counted: 86
Status: Success
Output saved to: output.txt
```

**Example 2: Advanced Usage**

**Input:**
```json
{
  "name": "test",
  "value": 123
}
```

**Command:**
```bash
python script.py -v --format json data.json
```

**Output:**
```
[VERBOSE] Loading configuration...
[VERBOSE] Parsing JSON input...
[VERBOSE] Processing data...
{
  "status": "success",
  "processed": true,
  "result": {
    "name": "test",
    "value": 123,
    "timestamp": "2024-02-07T10:30:00"
  }
}
[VERBOSE] Operation completed in 0.23s
```

---

## Project Demo

### Video
[Add your demo video link here - YouTube, Google Drive, etc.]

*Explain what the video demonstrates - key features, user flow, technical highlights*

### Additional Demos
[Add any extra demo materials/links - Live site, APK download, online demo, etc.]

---

## AI Tools Used (Optional - For Transparency Bonus)

If you used AI tools during development, document them here for transparency:

**Tool Used:** [e.g., GitHub Copilot, v0.dev, Cursor, ChatGPT, Claude]

**Purpose:** [What you used it for]
- Example: "Generated boilerplate React components"
- Example: "Debugging assistance for async functions"
- Example: "Code review and optimization suggestions"

**Key Prompts Used:**
- "Create a REST API endpoint for user authentication"
- "Debug this async function that's causing race conditions"
- "Optimize this database query for better performance"

**Percentage of AI-generated code:** [Approximately X%]

**Human Contributions:**
- Architecture design and planning
- Custom business logic implementation
- Integration and testing
- UI/UX design decisions

*Note: Proper documentation of AI usage demonstrates transparency and earns bonus points in evaluation!*

---

## Team Contributions

- [Name 1]: [Specific contributions - e.g., Frontend development, API integration, etc.]
- [Name 2]: [Specific contributions - e.g., Backend development, Database design, etc.]
- [Name 3]: [Specific contributions - e.g., UI/UX design, Testing, Documentation, etc.]

---

## License

This project is licensed under the [LICENSE_NAME] License - see the [LICENSE](LICENSE) file for details.

**Common License Options:**
- MIT License (Permissive, widely used)
- Apache 2.0 (Permissive with patent grant)
- GPL v3 (Copyleft, requires derivative works to be open source)

---

Made with ‚ù§Ô∏è at TinkerHub
